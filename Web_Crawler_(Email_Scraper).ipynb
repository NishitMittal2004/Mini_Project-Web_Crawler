{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NishitMittal2004/Mini_Project-Web_Crawler/blob/main/Web_Crawler_(Email_Scraper).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:04:35.948026Z",
          "iopub.status.busy": "2022-12-26T10:04:35.947633Z",
          "iopub.status.idle": "2022-12-26T10:05:06.892132Z",
          "shell.execute_reply": "2022-12-26T10:05:06.890969Z",
          "shell.execute_reply.started": "2022-12-26T10:04:35.947994Z"
        },
        "trusted": true,
        "id": "FNq6jU_HjaG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbcf761-c814-4a74-fd0b-5b3419991d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.27.1)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-1.1.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parse (from requests-html)\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bs4 (from requests-html)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting w3lib (from requests-html)\n",
            "  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2022.12.7)\n",
            "Collecting importlib-metadata>=1.4 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.65.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.26.15)\n",
            "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests-html) (4.11.2)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.2)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.15.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests-html) (2.4.1)\n",
            "Building wheels for collected packages: bs4, parse\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=b6a3a4501686f308c1276d5b1d1e63e9421dac2f0b41a2970b5b3c89fe3f8363\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24570 sha256=52f8ea2499f7e703a92d5b1cbfc5812bb9f86e4f5c66838f390df8230b4c3ef4\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4b/f0/eaf5a8de646d8676dc25caa01949b9f9d883b8fa2efb435bc3\n",
            "Successfully built bs4 parse\n",
            "Installing collected packages: pyee, parse, fake-useragent, websockets, w3lib, importlib-metadata, cssselect, pyquery, pyppeteer, bs4, requests-html\n",
            "Successfully installed bs4-0.0.1 cssselect-1.2.0 fake-useragent-1.1.3 importlib-metadata-6.6.0 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests-html-0.10.0 w3lib-2.1.1 websockets-10.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement request (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for request\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests-html\n",
        "!pip install re\n",
        "!pip install request\n",
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:06.904446Z",
          "iopub.status.busy": "2022-12-26T10:05:06.903610Z",
          "iopub.status.idle": "2022-12-26T10:05:06.918106Z",
          "shell.execute_reply": "2022-12-26T10:05:06.916982Z",
          "shell.execute_reply.started": "2022-12-26T10:05:06.904409Z"
        },
        "trusted": true,
        "id": "BPUO7soCjaHB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import deque\n",
        "from urllib.parse import urlsplit\n",
        "import pandas as pd\n",
        "from requests_html import HTMLSession\n",
        "import threading\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:06.921811Z",
          "iopub.status.busy": "2022-12-26T10:05:06.921045Z",
          "iopub.status.idle": "2022-12-26T10:05:06.933536Z",
          "shell.execute_reply": "2022-12-26T10:05:06.931924Z",
          "shell.execute_reply.started": "2022-12-26T10:05:06.921767Z"
        },
        "trusted": true,
        "id": "O8XrpB4WjaHF"
      },
      "outputs": [],
      "source": [
        "#user_url = \"https://www.thapar.edu/sitemap.xml\"\n",
        "#url = [\"https://www.thapar.edu\"]\n",
        "EMAIL_REGEX = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:06.936434Z",
          "iopub.status.busy": "2022-12-26T10:05:06.936048Z",
          "iopub.status.idle": "2022-12-26T10:05:09.351623Z",
          "shell.execute_reply": "2022-12-26T10:05:09.350425Z",
          "shell.execute_reply.started": "2022-12-26T10:05:06.936398Z"
        },
        "trusted": true,
        "id": "xw51GoK6jaHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e4a456-cb08-4862-8904-0eca73b43b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def get_urls_of_xml(xml_url):\n",
        "    r = requests.get(xml_url)\n",
        "    xml = r.text\n",
        "    soup = BeautifulSoup(xml)\n",
        "\n",
        "    links_arr = []\n",
        "    for link in soup.findAll('loc'):\n",
        "        linkstr = link.getText('', True)\n",
        "        links_arr.append(linkstr)\n",
        "\n",
        "    return links_arr\n",
        "\n",
        "\n",
        "\n",
        "links_data_arr = get_urls_of_xml(\"https://thapar.edu/sitemap.xml\")\n",
        "#print(links_data_arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:09.357183Z",
          "iopub.status.busy": "2022-12-26T10:05:09.356725Z",
          "iopub.status.idle": "2022-12-26T10:05:09.364213Z",
          "shell.execute_reply": "2022-12-26T10:05:09.362512Z",
          "shell.execute_reply.started": "2022-12-26T10:05:09.357144Z"
        },
        "trusted": true,
        "id": "2p6hNPpAjaHM"
      },
      "outputs": [],
      "source": [
        "session = HTMLSession()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:17.089462Z",
          "iopub.status.busy": "2022-12-26T10:05:17.089017Z",
          "iopub.status.idle": "2022-12-26T10:17:47.278602Z",
          "shell.execute_reply": "2022-12-26T10:17:47.277052Z",
          "shell.execute_reply.started": "2022-12-26T10:05:17.089423Z"
        },
        "trusted": true,
        "id": "i1gl4dsJjaHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc3f583-e14b-4a3f-b13a-10649905c8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 45/4342 [00:32<43:55,  1.63it/s]"
          ]
        }
      ],
      "source": [
        "email=set()\n",
        "for i in tqdm(links_data_arr):\n",
        "        #requests.get(f'{i}', verify=False)\n",
        "        r = session.get(i)\n",
        "        for re_match in re.finditer(EMAIL_REGEX, r.html.raw_html.decode()):\n",
        "            email.add(((re_match.group())).replace(\"-\",\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:18:56.632354Z",
          "iopub.status.busy": "2022-12-26T10:18:56.631963Z",
          "iopub.status.idle": "2022-12-26T10:18:56.641790Z",
          "shell.execute_reply": "2022-12-26T10:18:56.640417Z",
          "shell.execute_reply.started": "2022-12-26T10:18:56.632323Z"
        },
        "trusted": true,
        "id": "QY1HjTyfjaHQ"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(email)\n",
        "df.to_csv('Emails.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}